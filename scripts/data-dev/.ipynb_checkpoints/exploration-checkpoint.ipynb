{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text cleaning\n",
    "\n",
    "Aim is to try different scripts and libraries to clean text of various formats. \n",
    "\n",
    "**Don't forget to install the modules in requirements.txt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some challenges \n",
    "\n",
    "Challenges observed so far when it comes to preparing text for analysis:\n",
    "* Getting the structure from PDFs/XML in particular i.e. title, headings etc.\n",
    "* Removing/extracting noise e.g. page number integrated to text, footer will appear as many times as page number, reference numbers etc.\n",
    "* Extracting data based on tags is easy but each document has its custom structure, no general script to do this (although potentially transform into dictionary then keep keys that on average have the most text? or smth like this, but again might run into exceptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF\n",
    "\n",
    "sample_pdf_french_law.pdf is the French environmental code. Good example of how bills, articles, amendments, or treaties look like as a PDF (versus letter or manifesto, a lot of different heading, long documents etc.). However, they can be found in easier format than PDF and have often been extracted already.\n",
    "\n",
    "* PDF format\n",
    "* Just text but very structured, no tables or weird formatting\n",
    "* Will try to extract the text and categories based on the titles and headings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With PyPDF2 and regex\n",
    "\n",
    "This works fine but only extracts text, no structure. Ideally want to get headings etc. Can use regex for this, but very manual - there might be patterns accross most commonly used documents, for more custom structure, it can be described by the user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n",
      "ENVIRONMENTAL CODEthroughout the implementation phase of the projects referred to it, up to the rece\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "#text = textract.process(\"sample_pdf_french_law.pdf\")\n",
    "\n",
    "pdfFileObj = open('sample_pdf_french_law.pdf', 'rb')\n",
    "# read object\n",
    "\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "\n",
    "# print number of pages\n",
    "print(pdfReader.numPages)\n",
    "\n",
    "pageObj = pdfReader.getPage(1)\n",
    "print(pageObj.extractText()[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENVIRONMENTAL CODEthroughout the implementation phase of the projects referred to it, up to the receipt of equipment and works.€€€€€€€This Commission advises the competent authorities and any developer, at their request, on any question relating todialogue with the public throughout the development of the project.€€€€€€€The National Public Debate Commission is also entrusted with the role of issuing all and any opinions andrecommendations of a general or methodological nature likely to encourage and develop dialogue with the public.€€€€€€€The National Public Debate Commission and individual co\n"
     ]
    }
   ],
   "source": [
    "print(pageObj.extractText()[0:600])\n",
    "\n",
    "# ENVIRONMENTAL CODE = Top of page\n",
    "# €€€€€€€ = indent \n",
    "# Article XXXX = new article but also sometimes in text, so not enough to extract articles\n",
    "# Within articles: I. -, 1°, a)\n",
    "# Updated 04/10/2006 - Page XXX/XXX = end of page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With PDFminer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Useful scripts:**\n",
    "* convert pdf: https://gist.github.com/terencezl/61fe3f28c44a763dd1e9f060b8ff6f2e\n",
    "* get tags: https://gist.github.com/joelhsmith/5e6ec7ee70ab4b89d7bc5700e9e07fde\n",
    "* converting to html: https://stackoverflow.com/questions/3637781/converting-a-pdf-to-text-html-in-python-so-i-can-parse-it\n",
    "\n",
    "**Problem**: a lot of version of pdfminer, all those scripts use deprecated functions/modules. Tried pdfminer.six and pdfminer.3k but same story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdfminer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cb0bef51ea57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# a lot of version problems between scripts and package installed via pip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpdfminer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdfinterp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPDFResourceManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPDFPageInterpreter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpdfminer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextConverter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXMLConverter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHTMLConverter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpdfminer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLAParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pdfminer'"
     ]
    }
   ],
   "source": [
    "# INTERNAL ERRORS using pdfminer - doesn't look well maintained\n",
    "# a lot of version problems between scripts and package installed via pip\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter, XMLConverter, HTMLConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import BytesIO\n",
    "import ply \n",
    "\n",
    "def convert_pdf(path, format='text', password=''):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = BytesIO()\n",
    "    laparams = LAParams()\n",
    "    if format == 'text':\n",
    "        device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
    "    elif format == 'html':\n",
    "        device = HTMLConverter(rsrcmgr, retstr, laparams=laparams)\n",
    "    elif format == 'xml':\n",
    "        device = XMLConverter(rsrcmgr, retstr, laparams=laparams)\n",
    "    else:\n",
    "        raise ValueError('provide format, either text, html or xml!')\n",
    "    \n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "    \n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password, caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue().decode()\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# convert to text, print first 100 chars\n",
    "convert_pdf('sample_pdf_french_law.pdf')[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Tika\n",
    "\n",
    "This works really well in terms of keeping the structure (still need to figure out how to extract the different parts e.g. separate BOOK I and BOOK II). \n",
    "\n",
    "Very slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-25 11:35:00,083 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server/1.24/tika-server-1.24.jar to /var/folders/8g/jhnx9x0d2vxg4p121bvdz1gr0000gn/T/tika-server.jar.\n",
      "2020-06-25 11:35:19,650 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server/1.24/tika-server-1.24.jar.md5 to /var/folders/8g/jhnx9x0d2vxg4p121bvdz1gr0000gn/T/tika-server.jar.md5.\n",
      "2020-06-25 11:35:21,280 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ENVIRONMENTAL CODE\n",
      "\n",
      "With the cooperation of Michael Faure\n",
      "Professor of Comparative and International Environmental Law and Academic Director of METRO, the Institute for\n",
      "Transnational Legal Research of the Universiteit Maastricht.\n",
      "\n",
      "BOOK I\n",
      "Common provisions Articles L121-1 to\n",
      "\n",
      "L110-2\n",
      "Article L110-1\n",
      "(Act no. 2002-276 of 27 February 2002 Article 132 Official Journal of 28 February 2002)\n",
      "       I. - Natural areas, resources and habitats, sites and la\n"
     ]
    }
   ],
   "source": [
    "from tika import parser\n",
    "\n",
    "raw = parser.from_file('sample_pdf_french_law.pdf')\n",
    "raw.keys()\n",
    "print(raw['content'][50:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ublique.\n",
      "       In addition, the National Public Debate Commission ensures the upkeep of good conditions for informing the public\n",
      "</p>\n",
      "<p>Updated 04/10/2006 - Page 1/201</p>\n",
      "<p />\n",
      "</div>\n",
      "<div class=\"page\"><p />\n",
      "<p>ENVIRONMENTAL CODE\n",
      "throughout the implementation phase of the projects referred to it, up to the receipt of equipment and works.\n",
      "       This Commission advises the competent authorities and any developer, at their request, on any question relating to\n",
      "dialogue with the public throughout the development of the project.\n",
      "       The National Public Debate Commission is also entrusted with the role of issuing all and any opinions and\n",
      "recommendations of a general or methodological nature likely to encourage and develop dialogue with the public.\n",
      "       The National Public Debate Commission and individual commissions do not comment on the substance of the\n",
      "projects submitted to them.\n",
      "</p>\n",
      "<p>Article L121-2\n",
      "(Act no. 2002-276 of 27 February 2002 Article 134 Official Journal of 28 Februar\n"
     ]
    }
   ],
   "source": [
    "# setting xmlContent=True adds the html markup which can be useful to detect titles, paragraphs etc.\n",
    "# can then separate the parts using custom script e.g. https://cbrownley.wordpress.com/2016/06/26/parsing-pdfs-in-python-with-tika/\n",
    "\n",
    "raw_xml = parser.from_file('sample_pdf_french_law.pdf', xmlContent=True)\n",
    "print(raw_xml['content'][6000:7000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying it again with a more complex PDF, **manifesto of the AFD (Austria)** which has images and a lot of formating. \n",
    "* Surprisingly fast \n",
    "* But order of elements is messy (e.g. name of the author of the foreword is located far from the foreword)\n",
    "* Recognizes paragraphs but sometimes weirdly because of formatting (e.g. if there is a picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out 1\n",
      "\n",
      "\n",
      "Freiheitliches Wahlprogramm \n",
      "zur Nationalratswahl 2017\n",
      "\n",
      "\n",
      "\n",
      "100 FPÖ-Forderungen zur \n",
      "Beseitigung der Fairness-Krise\n",
      "Österreicher verdienen Fairness. Denn Österreich durchleidet spürbar eine massive\n",
      "Fairnesskrise. Wir haben die höchste Steuerbelastung bei einem aufgeblähten\n",
      "Staatsapparat, eine Einschränkung aller Freiheitsräume durch Überregulierung (Ge-\n",
      "werbeordnung, überbordende Gesetzesflut) und eine doppelte Umverteilung: einer-\n",
      "\n",
      "seits v\n"
     ]
    }
   ],
   "source": [
    "from tika import parser\n",
    "\n",
    "raw = parser.from_file('sample_pdf_afd_manifesto.pdf')\n",
    "raw.keys()\n",
    "print(raw['content'][50:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With PyMuPDF\n",
    "\n",
    "Good explanation here: https://towardsdatascience.com/extracting-headers-and-paragraphs-from-pdf-using-pymupdf-676e8421c467\n",
    "\n",
    "Most advanced library to extract headings / structure so far, but not great with messy PDFs - not as straightforward as it seems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(\"sample_pdf_french_law.pdf\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31.190000534057617,\n",
       " 244.5900421142578,\n",
       " 564.0989379882812,\n",
       " 303.6300048828125,\n",
       " 'Article L121-14\\n(Inserted by Act no. 2002-276 of 27 February 2002 Article 134 Official Journal of 28 February 2002)\\n       No irregularity with regard to the provisions of the present Chapter may be invoked when the notice by which the\\nNational Public Debate Commission has opted not to organise a public debate or the notice mentioned in Article L.\\n121-13 has become final.',\n",
       " 2,\n",
       " 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = doc[3]\n",
    "text = page.getText(\"blocks\") # can also use html, dict, xml, xhtml, raw text, blocks works pretty well with list of articles / bills\n",
    "text[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with the other samle pdf. Same as before, useful if formating is on point, requires quite a bit of human effort to check/indicate what headings might be. Ok if formatting is the same accross all pages, a pain otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(56.692901611328125,\n",
       "  110.83820343017578,\n",
       "  412.9449157714844,\n",
       "  171.78221130371094,\n",
       "  'Unsere Souveränität \\nund Selbstbestimmung schützen',\n",
       "  0,\n",
       "  0),\n",
       " (56.69260025024414,\n",
       "  226.3517608642578,\n",
       "  291.9969787597656,\n",
       "  452.3187255859375,\n",
       "  'E\\ns entspricht freiheitlicher Geisteshaltung, dem\\neinzelnen Menschen die Freiheit als höchstes\\nGut einzuräumen und darin gleichzeitig einen un-\\nverzichtbaren Wert zu sehen.  Der einzelne Mensch\\nist jedoch stets in eine Gemeinschaft gestellt, die\\nebenfalls selbständig Träger von Freiheitsrechten\\nist – von der Familie bis zum Volk. Wir Freiheitliche\\nsind daher bestrebt, eine Gesellschaftsordnung zu\\nverwirklichen, die dem Einzelnen einen durch\\nGrund- und Freiheitsrechte garantierten, staats-\\nfreien Raum gewährleistet. Auf der anderen Seite\\nwollen wir unsere Heimat als möglichst autonomen\\nund autarken Staat in der internationalen Staaten-\\ngemeinschaft etabliert wissen.',\n",
       "  1,\n",
       "  0)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = fitz.open(\"sample_pdf_afd_manifesto.pdf\")     \n",
    "page = doc[3]\n",
    "text = page.getText(\"blocks\") # can also use html, dict, xml, xhtml, raw text, blocks works pretty well with list of articles / bills\n",
    "text[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON\n",
    "\n",
    "GET request to UK Parliament API to see what it returns (how clean, how straightforward it is etc.).\n",
    "\n",
    "Very easy to use, text is clean, metadata is easy to store in panda df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"http://lda.data.parliament.uk/lordswrittenquestions.json?_view=Written+Questions&_pageSize=500&_page=0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_text(response):\n",
    "    \n",
    "    response_json = json.loads(response.text)['result']['items']\n",
    "    df = pd.DataFrame({'AnswerDate': [response_json[i]['AnswerDate']['_value'] for i in range(len(response_json))],\n",
    "                       'AnsweringBody': [response_json[i]['AnsweringBody'][0]['_value'] for i in range(len(response_json))],\n",
    "                       'questionText': [response_json[i]['questionText'] for i in range(len(response_json))],\n",
    "                       'tablingMember': [response_json[i]['tablingMemberPrinted'][0]['_value'] for i in range(len(response_json))]})\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnswerDate</th>\n",
       "      <th>AnsweringBody</th>\n",
       "      <th>questionText</th>\n",
       "      <th>tablingMember</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>Foreign and Commonwealth Office</td>\n",
       "      <td>To ask Her Majesty's Government what assessmen...</td>\n",
       "      <td>Lord Alton of Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>Foreign and Commonwealth Office</td>\n",
       "      <td>To ask Her Majesty's Government, further to re...</td>\n",
       "      <td>Lord Alton of Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>Home Office</td>\n",
       "      <td>To ask Her Majesty's Government what measures ...</td>\n",
       "      <td>Lord Alton of Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>Foreign and Commonwealth Office</td>\n",
       "      <td>To ask Her Majesty's Government what assessmen...</td>\n",
       "      <td>Lord Alton of Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>Foreign and Commonwealth Office</td>\n",
       "      <td>To ask Her Majesty's Government what plans the...</td>\n",
       "      <td>Lord Alton of Liverpool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>Department of Health and Social Care</td>\n",
       "      <td>Her Majesty's Government how they will ensure ...</td>\n",
       "      <td>Lord Roberts of Llandudno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>Department for International Trade</td>\n",
       "      <td>To ask Her Majesty's Government what discussio...</td>\n",
       "      <td>Lord Roberts of Llandudno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>Department of Health and Social Care</td>\n",
       "      <td>Her Majesty's Government what assessment they ...</td>\n",
       "      <td>Lord Roberts of Llandudno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>Department for Work and Pensions</td>\n",
       "      <td>To ask Her Majesty's Government what plans the...</td>\n",
       "      <td>Lord Roberts of Llandudno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>Cabinet Office</td>\n",
       "      <td>Her Majesty's Government what plans they have ...</td>\n",
       "      <td>Lord Roberts of Llandudno</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AnswerDate                         AnsweringBody  \\\n",
       "0    2020-07-08       Foreign and Commonwealth Office   \n",
       "1    2020-07-08       Foreign and Commonwealth Office   \n",
       "2    2020-07-08                           Home Office   \n",
       "3    2020-07-08       Foreign and Commonwealth Office   \n",
       "4    2020-07-08       Foreign and Commonwealth Office   \n",
       "..          ...                                   ...   \n",
       "495  2020-06-29  Department of Health and Social Care   \n",
       "496  2020-06-29    Department for International Trade   \n",
       "497  2020-06-29  Department of Health and Social Care   \n",
       "498  2020-06-29      Department for Work and Pensions   \n",
       "499  2020-06-29                        Cabinet Office   \n",
       "\n",
       "                                          questionText  \\\n",
       "0    To ask Her Majesty's Government what assessmen...   \n",
       "1    To ask Her Majesty's Government, further to re...   \n",
       "2    To ask Her Majesty's Government what measures ...   \n",
       "3    To ask Her Majesty's Government what assessmen...   \n",
       "4    To ask Her Majesty's Government what plans the...   \n",
       "..                                                 ...   \n",
       "495  Her Majesty's Government how they will ensure ...   \n",
       "496  To ask Her Majesty's Government what discussio...   \n",
       "497  Her Majesty's Government what assessment they ...   \n",
       "498  To ask Her Majesty's Government what plans the...   \n",
       "499  Her Majesty's Government what plans they have ...   \n",
       "\n",
       "                 tablingMember  \n",
       "0      Lord Alton of Liverpool  \n",
       "1      Lord Alton of Liverpool  \n",
       "2      Lord Alton of Liverpool  \n",
       "3      Lord Alton of Liverpool  \n",
       "4      Lord Alton of Liverpool  \n",
       "..                         ...  \n",
       "495  Lord Roberts of Llandudno  \n",
       "496  Lord Roberts of Llandudno  \n",
       "497  Lord Roberts of Llandudno  \n",
       "498  Lord Roberts of Llandudno  \n",
       "499  Lord Roberts of Llandudno  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML\n",
    "\n",
    "Sample file is the proceedings from the Welsh Record of Proceedings from the Culture, Welsh Language and Communications Committee (11/06/2020 13:29)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('sample_xml_welsh_parl.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XML_CultureWelshLanguageAndCommunicationsCommittee_English',\n",
       " 'Meeting_ID',\n",
       " 'Assembly',\n",
       " 'MeetingDate',\n",
       " 'Contribution_ID',\n",
       " 'Contribution_Order_ID',\n",
       " 'contribution_language',\n",
       " 'ContributionTime',\n",
       " 'contribution_spoken_seneddTv',\n",
       " 'contribution_translated_seneddTv',\n",
       " 'Agenda_Item_ID',\n",
       " 'Agenda_item_welsh',\n",
       " 'Agenda_item_english',\n",
       " 'contribution_type',\n",
       " 'Attendee_Id',\n",
       " 'Member_Id',\n",
       " 'Member_name_English',\n",
       " 'Member_biog_English',\n",
       " 'Member_biog_Welsh',\n",
       " 'Member_job_title_English',\n",
       " 'Member_job_title_Welsh',\n",
       " 'Contribution_English',\n",
       " 'Contribution_Welsh',\n",
       " 'contribution_verbatim',\n",
       " 'contribution_translated']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tree for first element\n",
    "[elem.tag for elem in root[0].iter()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<?xml version=\\'1.0\\' encoding=\\'utf8\\'?>\\n<dataroot generated=\"2020-06-12T15:33:07\">\\n  <XML_CultureWelshLanguageAndCommunicationsCommittee_English>\\n    <Meeting_ID>6356</Meeting_ID>\\n    <Assembly>5</Assembly>\\n    <MeetingDate>2020-06-11T13:29:46</MeetingDate>\\n    <Contribution_ID>293839</Contribution_ID>\\n    <Contribution_Order_ID>0</Contribution_Order_ID>\\n    <contribution_language>Cy</contribution_language>\\n    <ContributionTime />\\n    <contribution_spoken_seneddTv />\\n    <contribution_translated_seneddTv />\\n    <Agenda_Item_ID>200611-0</Agenda_Item_ID>\\n    <Agenda_item_welsh />\\n    <Agenda_item_english />\\n    <contribution_type>I</contribution_type>\\n    <Attendee_Id />\\n    <Member_Id />\\n    <Member_name_English />\\n    <Member_biog_English />\\n    <Member_biog_Welsh />\\n    <Member_job_title_English />\\n    <Member_job_title_Welsh />\\n    <Contribution_English>&lt;p&gt;The proceedings are reported in the language in which they were spoken in the committee. In addition, a transcription of the'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ET.tostring(root, encoding='utf8').decode('utf8'))[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easier to work with as a dictionary -> convert and export as json\n",
    "\n",
    "import xmltodict\n",
    "import json\n",
    "with open('sample_xml_welsh_parl.xml') as in_file:\n",
    "    xml = in_file.read()\n",
    "    with open('transformed_welsh_parl.json', 'w') as out_file:\n",
    "        json_file = json.dump(xmltodict.parse(xml), out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transformed_welsh_parl.json') as in_file:\n",
    "    json_wales = json.loads(in_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<p>The proceedings are reported in the language in which they were spoken in the committee. In addition, a transcription of the simultaneous interpretation is included. This is a draft version of the record. The final version will be published within five working days.</p>',\n",
       " '<p>The committee met by video-conference.</p>\\n<p>The meeting began at 13:29.</p>',\n",
       " \"<p>Good afternoon, everyone, and a warm welcome to this meeting of the Culture, Welsh Language and Communications Committee at our Senedd. In accordance with Standing Order 34.19, I have determined that the public are excluded from attending this committee meeting in order to protect public health. This meeting is, however, being broadcast live on Senedd.tv, with all participants joining via video-conference. A transcript of the meeting will be published as usual. Aside from the procedure adaptations relating to conducting proceedings remotely, all other Standing Order requirements remain in place. This meeting is bilingual, with simultaneous interpretation from Welsh to English available. I'll ask Members if there are any declarations of interest. There are none. Thank you.</p>\\n<p>And therefore, just so that you are aware, if there is a problem with my technology and I have to drop out of the meeting for any reason, the committee has agreed that David Melding will temporarily chair while I try and rejoin the meeting.</p>\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_text = [json_wales[\"dataroot\"]['XML_CultureWelshLanguageAndCommunicationsCommittee_English'][i][\"Contribution_English\"] for i in range(len(json_wales[\"dataroot\"]['XML_CultureWelshLanguageAndCommunicationsCommittee_English']))]\n",
    "english_text[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New sample, more complex XML **Written Questions to the Ministers (France)**. There is more nesting and each XML contains one question. \n",
    "* Straightforward for a human, harder for a machine\n",
    "* If they keys have a clear name (e.g. text) then it's very easy (even for a machine? at first just grep anything that sounds like text OR based on length of values for each key -> in the future ML? although very idiosyncratic)\n",
    "* Potentially print all keys and build structure and ask the user to select where the text is, but not very scalable\n",
    "* Tree doesn't work in this case so convert to dictionary is useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('sample_xml_france_parl.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{http://schemas.assemblee-nationale.fr/referentiel}uid']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tree for first element\n",
    "[elem.tag for elem in root[0].iter()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import json\n",
    "with open('sample_xml_france_parl.xml') as in_file:\n",
    "    xml = in_file.read()\n",
    "    with open('sample_xml_france_parl.json', 'w') as out_file:\n",
    "        json_file = json.dump(xmltodict.parse(xml), out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample_xml_france_parl.json') as in_file:\n",
    "    json_wales = json.loads(in_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['@xmlns', '@xmlns:xsi', '@xsi:type', 'uid', 'identifiant', 'type', 'indexationAN', 'auteur', 'minInt', 'minAttribs', 'textesQuestion', 'textesReponse', 'cloture', 'signalement', 'renouvellements'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_wales.keys() # dict_keys(['question'])\n",
    "json_wales['question'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"M. Antoine Herth attire l'attention de M. le ministre d'État, ministre de l'intérieur, sur les diffi\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question\n",
    "json_wales['question']['textesQuestion']['texteQuestion']['texte'][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Le déploiement des télé-procédures dans le cadre du plan préfecture nouvelle génération (PPNG) a int'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer\n",
    "json_wales['question']['textesReponse']['texteReponse']['texte'][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sage",
   "language": "python",
   "name": "sage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
